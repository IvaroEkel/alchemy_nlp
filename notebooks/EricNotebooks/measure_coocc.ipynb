{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to Dataframe\n",
    "#### Script Purpose\n",
    "In this sample script, we will convert the input dataset into a pandas dataframe containing the filename, title, and publication date of each document.\n",
    "\n",
    "#### Expected Runtime and Sample Size\n",
    "Mileage will vary depending on document size and resources available. For 1000 New York Times articles, expect around 16 seconds for this script to complete. For 1000 dissertations, expect around 20 seconds for this script to complete. The current starting sample size is set to 100 documents so that the script will run in real time for demonstration purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for parsing data\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "from lxml import etree\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Sample Data\n",
    "\n",
    "Depending on the size and vocabulary of the input dataset, runtime of this script may vary. To process the entire dataset, set `sample_size` to `len(input_files)`. Larger datasets can be run on the multiprocessing version of this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 180 documents.\n"
     ]
    }
   ],
   "source": [
    "# Set corpus to the folder of files you want to use\n",
    "corpus = '/home/ec2-user/SageMaker/data/AlchemyData/'\n",
    "\n",
    "# Read in files\n",
    "input_files = os.listdir(corpus)\n",
    "\n",
    "print(\"Loaded\", len(input_files), \"documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently sampling 180 documents.\n"
     ]
    }
   ],
   "source": [
    "# Select the number of articles to sample\n",
    "sample_size = 180\n",
    "\n",
    "# Generate a sample of articles\n",
    "try:\n",
    "    sample_input_files = input_files[0:sample_size]\n",
    "\n",
    "except ValueError:\n",
    "    sample_input_files = input_files\n",
    "    \n",
    "print(\"Currently sampling\", len(sample_input_files), \"documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Output File\n",
    "\n",
    "Define the `output_file` variable to the desired save location and file name. This variable will be used at the end of the script to save the processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asdf\n"
     ]
    }
   ],
   "source": [
    "# Modify output_file to desired save name\n",
    "output_file = 'output_files/coocc.csv.gz'\n",
    "print('asdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather Metadata Fields\n",
    "\n",
    "This section will gather text fields from the articles and add them to lists that will be used to make a dataframe. By default, this script will collect article ID, title, and the publishing date of the articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to strip html tags from text portion\n",
    "def strip_html_tags(text):\n",
    "    stripped = BeautifulSoup(text).get_text().replace('\\n', ' ').replace('\\\\', '').strip()\n",
    "    return stripped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve metadata from XML document\n",
    "def getxmlcontent(corpus, file, strip_html=True):\n",
    "    try:\n",
    "        tree = etree.parse(corpus + file)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        if root.find('.//GOID') is not None:\n",
    "            goid = root.find('.//GOID').text\n",
    "        else:\n",
    "            goid = None\n",
    "\n",
    "        if root.find('.//Title') is not None:\n",
    "            title = root.find('.//Title').text\n",
    "        else:\n",
    "            title = None\n",
    "\n",
    "        if root.find('.//NumericDate') is not None:\n",
    "            date = root.find('.//NumericDate').text\n",
    "        else:\n",
    "            date = None\n",
    "            \n",
    "        if root.find('.//PublisherName') is not None:\n",
    "            publisher = root.find('.//PublisherName').text\n",
    "        else:\n",
    "            publisher = None\n",
    "\n",
    "        if root.find('.//FullText') is not None:\n",
    "            text = root.find('.//FullText').text\n",
    "\n",
    "        elif root.find('.//HiddenText') is not None:\n",
    "            text = root.find('.//HiddenText').text\n",
    "\n",
    "        elif root.find('.//Text') is not None:\n",
    "            text = root.find('.//Text').text\n",
    "\n",
    "        else:\n",
    "            text = None\n",
    "\n",
    "        # Strip html from text portion\n",
    "        if text is not None and strip_html == True:\n",
    "            text = strip_html_tags(text)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error while parsing file {file}: {e}\")\n",
    "    \n",
    "    return title, date, publisher, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(list):\n",
    "    pattern = '[0-9]'\n",
    "    list = [re.sub(pattern, '',i) for i in list]\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fragments(text):\n",
    "    #Turns the file contents into a list of words, and makes them all lowercase\n",
    "    casedtext = re.findall(r'\\w+', text)\n",
    "    lowertext = [item.lower() for item in casedtext]\n",
    "    lowertext = [value for value in lowertext if value != \"page\" and value != \"image\"]\n",
    "    lowertext = remove_numbers(lowertext)\n",
    "\n",
    "    # Number of words being searched around each term occurrence\n",
    "    neighbors_range = 5\n",
    "\n",
    "    # Words that equate to mercury\n",
    "    mercury_terms = ['argent', 'mercury', 'quicksilver']\n",
    "\n",
    "    # Number of times each term appears in the text\n",
    "    m_occ = sum('mercury' in s for s in lowertext) + sum('argent' in s for s in lowertext) + sum('quicksilver' in s for s in lowertext)\n",
    "    s_occ = sum('sulphur' in s for s in lowertext)\n",
    "    l_occ = sum('salt' in s for s in lowertext)\n",
    "\n",
    "    text_fragments = []\n",
    "    fragment_sample = []\n",
    "    sample_num = 7\n",
    "\n",
    "    # Tracks co-occurrences of the terms. The leading letter is the \"main term\".\n",
    "    m_s_coocc = 0\n",
    "    m_l_coocc = 0\n",
    "    m_s_l_coocc = 0\n",
    "\n",
    "    s_l_coocc = 0\n",
    "    s_m_coocc = 0\n",
    "    s_m_l_coocc = 0\n",
    "\n",
    "    l_s_coocc = 0\n",
    "    l_m_coocc = 0\n",
    "    l_s_m_coocc = 0\n",
    "\n",
    "    # Lists storing the index of each occurrence of mercury or sulphur\n",
    "    mercury_indexes = []\n",
    "    sulphur_indexes = []\n",
    "\n",
    "    # Lists storing the distances between each occurrence of the first term and the next occurrence of the second term\n",
    "    m_m_distances = []\n",
    "    m_s_distances = []\n",
    "    s_m_distances = []\n",
    "    s_s_distances = []\n",
    "\n",
    "    def check_mercury(word):\n",
    "      for i in mercury_terms: \n",
    "        if i in word: \n",
    "          return True\n",
    "      return False\n",
    "\n",
    "    # Iterates through each word in the text, and any of the words contains a mercury term, then it creates a neighborhood (the 5 words before + the term + the 5 words after). This tracks how many times salt or sulphur occur in the same set of words as mercury.\n",
    "    # MERCURY\n",
    "    for i in range(len(lowertext)):\n",
    "      if check_mercury(lowertext[i]): \n",
    "          neighbors = ' '.join(lowertext[i-neighbors_range:i+neighbors_range + 1])\n",
    "          mercury_indexes.append(i)\n",
    "          text_fragments.append(neighbors)\n",
    "          if 'salt' in neighbors and 'sulphur' in neighbors: \n",
    "            m_s_l_coocc+= 1\n",
    "            m_s_coocc += 1\n",
    "            m_l_coocc += 1\n",
    "          elif 'salt' in neighbors: \n",
    "            m_l_coocc += 1\n",
    "          elif 'sulphur' in neighbors: \n",
    "            m_s_coocc += 1\n",
    "\n",
    "    # SULPHUR\n",
    "    for i in range(len(lowertext)):\n",
    "      if 'sulphur' in lowertext[i]: \n",
    "        neighbors = ' '.join(lowertext[i-neighbors_range:i+neighbors_range+ 1])\n",
    "        sulphur_indexes.append(i)\n",
    "        text_fragments.append(neighbors)\n",
    "        if 'salt' in neighbors and ('mercury' in neighbors or 'argent' in neighbors or 'quicksilver' in neighbors): \n",
    "          s_m_l_coocc+= 1\n",
    "          s_l_coocc += 1\n",
    "          s_m_coocc += 1\n",
    "        elif 'salt' in neighbors: \n",
    "          s_l_coocc += 1\n",
    "        elif mercury_terms[0] in neighbors or mercury_terms[1] in neighbors  or mercury_terms[2] in neighbors: \n",
    "          s_m_coocc += 1\n",
    "\n",
    "    # SALT\n",
    "    for i in range(len(lowertext)):\n",
    "      if 'salt' in lowertext[i]: \n",
    "        neighbors = ' '.join(lowertext[i-neighbors_range:i+neighbors_range+ 1])\n",
    "        text_fragments.append(neighbors)\n",
    "        if 'sulphur' in neighbors and ('mercury' in neighbors or 'argent' in neighbors  or 'quicksilver' in neighbors): \n",
    "          l_s_m_coocc+= 1\n",
    "          l_s_coocc += 1\n",
    "          l_m_coocc += 1\n",
    "        elif 'sulphur' in neighbors:\n",
    "          l_s_coocc += 1\n",
    "        elif mercury_terms[0] in neighbors or mercury_terms[1] in neighbors  or mercury_terms[2] in neighbors:\n",
    "          l_m_coocc += 1\n",
    "    \n",
    "    if len(text_fragments) < sample_num: return []\n",
    "    else:\n",
    "        for i in random.sample(text_fragments, sample_num):\n",
    "          fragment_sample.append(i)\n",
    "        return fragment_sample, m_occ, s_occ, l_occ, m_s_coocc, m_l_coocc, m_s_l_coocc, s_l_coocc, s_m_coocc, s_m_l_coocc, l_s_coocc, l_m_coocc, l_s_m_coocc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asdf\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "Error\n",
      "41\n",
      "42\n",
      "Error\n",
      "Error\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "Error\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "Error\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "Error\n",
      "94\n",
      "95\n",
      "Error\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "Error\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "Error\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "Error\n",
      "114\n",
      "Error\n",
      "Error while parsing file .ipynb_checkpoints: Document is empty, line 1, column 1 (.ipynb_checkpoints, line 1)\n",
      "Error\n",
      "115\n",
      "116\n",
      "Error\n",
      "Error\n",
      "117\n",
      "118\n",
      "Error\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "Error\n",
      "Error\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "Error\n",
      "157\n",
      "158\n",
      "159\n"
     ]
    }
   ],
   "source": [
    "# Create lists to store article IDs, titles, dates, and text\n",
    "print(\"asdf\")\n",
    "title_list = []\n",
    "date_list = []\n",
    "text_list = []\n",
    "fragments_list = []\n",
    "publisher_list = []\n",
    "m_list = []\n",
    "s_list = []\n",
    "l_list = []\n",
    "m_s_list = []\n",
    "m_l_list = []\n",
    "m_s_l_list = []\n",
    "s_l_list = []\n",
    "s_m_list = []\n",
    "s_m_l_list = []\n",
    "l_s_list = []\n",
    "l_m_list = [] \n",
    "l_s_m_list = []\n",
    "\n",
    "docs_count = 0\n",
    "\n",
    "\n",
    "# Parse files and add data to lists\n",
    "for file in sample_input_files:  \n",
    "    try:\n",
    "        # Retrieve the metadata\n",
    "        title, date, publisher, text = getxmlcontent(corpus, file, strip_html=True)\n",
    "\n",
    "        fragments, m, s, l, m_s, m_l, m_s_l, s_l, s_m, s_m_l, l_s, l_m, l_s_m = get_fragments(text)\n",
    "\n",
    "        # Store metadata to lists\n",
    "        title_list.append(title)\n",
    "        date_list.append(date)\n",
    "        publisher_list.append(publisher)\n",
    "\n",
    "        docs_count += 1\n",
    "        print(docs_count)\n",
    "            \n",
    "\n",
    "        # Co-occurrences\n",
    "        m_list.append(m)\n",
    "        s_list.append(s)\n",
    "        l_list.append(l)\n",
    "        m_s_list.append(m_s)\n",
    "        m_l_list.append(m_l)\n",
    "        m_s_l_list.append(m_s_l)\n",
    "        s_l_list.append(s_l)\n",
    "        s_m_list.append(s_m)\n",
    "        s_m_l_list.append(s_m_l)\n",
    "        l_s_list.append(l_s)\n",
    "        l_m_list.append(l_m)\n",
    "        l_s_m_list.append(l_s_m)\n",
    "\n",
    "    except:\n",
    "        print('Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframe\n",
    "\n",
    "This section uses the collected fields to make a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a dataframe, setting each of the columns to one of the lists made in the cell above\n",
    "df = pd.DataFrame({'Title': title_list, 'Date': date_list, 'Mercury Occurrences' : m_list, 'Sulphur Occurrences' : s_list, 'Salt Occurrences': l_list, 'M-S': m_s_list, 'M-L': m_l_list, 'M-S-L': m_s_l_list, 'S-L': s_l_list, 'S-M': s_m_list, 'S-M-L': s_m_l_list, 'L-S': l_s_list, 'L-M': l_m_list, 'L-S-M': l_s_m_list })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Mercury Occurrences</th>\n",
       "      <th>Sulphur Occurrences</th>\n",
       "      <th>Salt Occurrences</th>\n",
       "      <th>M-S</th>\n",
       "      <th>M-L</th>\n",
       "      <th>M-S-L</th>\n",
       "      <th>S-L</th>\n",
       "      <th>S-M</th>\n",
       "      <th>S-M-L</th>\n",
       "      <th>L-S</th>\n",
       "      <th>L-M</th>\n",
       "      <th>L-S-M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Medicinal experiments, or, A collection of cho...</td>\n",
       "      <td>1693-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chymical secrets and rare experiments in physi...</td>\n",
       "      <td>1683-01-01</td>\n",
       "      <td>12</td>\n",
       "      <td>154</td>\n",
       "      <td>356</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Observations on the mineral waters of France m...</td>\n",
       "      <td>1684-01-01</td>\n",
       "      <td>18</td>\n",
       "      <td>64</td>\n",
       "      <td>360</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A letter in answer to certain quæries and obje...</td>\n",
       "      <td>1670-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paracelsus his Aurora, &amp; treasure of the philo...</td>\n",
       "      <td>1659-01-01</td>\n",
       "      <td>47</td>\n",
       "      <td>43</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>A treatise of Lewisham (but vulgarly miscalled...</td>\n",
       "      <td>1680-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Vindiciæ literarum, the schools guarded, or, T...</td>\n",
       "      <td>1655-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Tryon's letters upon several occasions ... by ...</td>\n",
       "      <td>1700-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>The anatomy of human bodies, comprehending the...</td>\n",
       "      <td>1694-01-01</td>\n",
       "      <td>30</td>\n",
       "      <td>215</td>\n",
       "      <td>477</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Chirurgorum comes, or, The whole practice of c...</td>\n",
       "      <td>1687-01-01</td>\n",
       "      <td>52</td>\n",
       "      <td>38</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title        Date  \\\n",
       "0    Medicinal experiments, or, A collection of cho...  1693-01-01   \n",
       "1    Chymical secrets and rare experiments in physi...  1683-01-01   \n",
       "2    Observations on the mineral waters of France m...  1684-01-01   \n",
       "3    A letter in answer to certain quæries and obje...  1670-01-01   \n",
       "4    Paracelsus his Aurora, & treasure of the philo...  1659-01-01   \n",
       "..                                                 ...         ...   \n",
       "154  A treatise of Lewisham (but vulgarly miscalled...  1680-01-01   \n",
       "155  Vindiciæ literarum, the schools guarded, or, T...  1655-01-01   \n",
       "156  Tryon's letters upon several occasions ... by ...  1700-01-01   \n",
       "157  The anatomy of human bodies, comprehending the...  1694-01-01   \n",
       "158  Chirurgorum comes, or, The whole practice of c...  1687-01-01   \n",
       "\n",
       "     Mercury Occurrences  Sulphur Occurrences  Salt Occurrences  M-S  M-L  \\\n",
       "0                      5                   14                26    2    1   \n",
       "1                     12                  154               356    2    3   \n",
       "2                     18                   64               360    1    3   \n",
       "3                      5                    5                 9    2    3   \n",
       "4                     47                   43                33   12    3   \n",
       "..                   ...                  ...               ...  ...  ...   \n",
       "154                    4                   15                52    1    2   \n",
       "155                    6                    2                 4    1    1   \n",
       "156                    5                   11                36    2    2   \n",
       "157                   30                  215               477    4    3   \n",
       "158                   52                   38               108    5    7   \n",
       "\n",
       "     M-S-L  S-L  S-M  S-M-L  L-S  L-M  L-S-M  \n",
       "0        1    1    2      1    1    1      1  \n",
       "1        2    7    2      2    8    4      2  \n",
       "2        1   25    1      1   30    3      1  \n",
       "3        2    2    2      2    2    3      2  \n",
       "4        1    7   13      2    7    3      1  \n",
       "..     ...  ...  ...    ...  ...  ...    ...  \n",
       "154      1    3    1      1    3    2      1  \n",
       "155      1    2    1      1    2    1      1  \n",
       "156      2    2    2      2    2    2      2  \n",
       "157      2   71    4      3   70    3      3  \n",
       "158      3    3    5      3    4    8      4  \n",
       "\n",
       "[159 rows x 14 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Dataframe as CSV\n",
    "\n",
    "Make sure to change the `output_file` variable (defined at the top of script) to desired output file name before running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output to file\n",
    "df.to_csv(output_file, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sample-2022.05.25",
   "language": "python",
   "name": "sample-2022.05.25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
