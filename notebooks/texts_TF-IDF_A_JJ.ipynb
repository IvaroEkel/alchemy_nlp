{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "os.chdir('../scr/')\n",
    "%run setup.py\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load labeled 11 word fragments table\n",
    "os.chdir('../alchemy_texts/')\n",
    "data = pd.read_csv('../alchemy_texts/filtered_training_set_2.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load texts_aka_compressed_documents.csv\n",
    "texts = pd.read_csv('../alchemy_texts/filtered_training_set.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                                        Title  Year  \\\nUnnamed: 0                                                            \n174         Vindiciæ literarum, the schools guarded, or, T...  1655   \n43          Proposals for the printing an entire course or...  1693   \n155         The way to the Sabbath of rest, or, The souls ...  1692   \n41          A compleat history of the most remarkable prov...  1697   \n164         Fœlix consortium, or, A fit conjuncture of rel...  1663   \n\n            Predictions  Principles Predictions % Principles  \\\nUnnamed: 0                                                     \n174                  12                       0        0.00%   \n43                    3                       0        0.00%   \n155                   6                       4       66.67%   \n41                  127                       1        0.79%   \n164                  71                       0        0.00%   \n\n            Lab/Ops Predictions % Lab/Ops       diff     diff %  \\\nUnnamed: 0                                                        \n174                           8    66.67%  66.666667  33.333333   \n43                            2    66.67%  66.666667  33.333333   \n155                           0     0.00%  66.666667  33.333333   \n41                           86    67.72%  68.503937  31.496063   \n164                          49    69.01%  69.014085  30.985915   \n\n            Both Less Than 50%  If Principles  If Labs/Ops  \nUnnamed: 0                                                  \n174                      False              1            0  \n43                       False              1            0  \n155                      False              0            1  \n41                       False              1            0  \n164                      False              1            0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Year</th>\n      <th>Predictions</th>\n      <th>Principles Predictions</th>\n      <th>% Principles</th>\n      <th>Lab/Ops Predictions</th>\n      <th>% Lab/Ops</th>\n      <th>diff</th>\n      <th>diff %</th>\n      <th>Both Less Than 50%</th>\n      <th>If Principles</th>\n      <th>If Labs/Ops</th>\n    </tr>\n    <tr>\n      <th>Unnamed: 0</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>174</th>\n      <td>Vindiciæ literarum, the schools guarded, or, T...</td>\n      <td>1655</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0.00%</td>\n      <td>8</td>\n      <td>66.67%</td>\n      <td>66.666667</td>\n      <td>33.333333</td>\n      <td>False</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>Proposals for the printing an entire course or...</td>\n      <td>1693</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0.00%</td>\n      <td>2</td>\n      <td>66.67%</td>\n      <td>66.666667</td>\n      <td>33.333333</td>\n      <td>False</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>155</th>\n      <td>The way to the Sabbath of rest, or, The souls ...</td>\n      <td>1692</td>\n      <td>6</td>\n      <td>4</td>\n      <td>66.67%</td>\n      <td>0</td>\n      <td>0.00%</td>\n      <td>66.666667</td>\n      <td>33.333333</td>\n      <td>False</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>A compleat history of the most remarkable prov...</td>\n      <td>1697</td>\n      <td>127</td>\n      <td>1</td>\n      <td>0.79%</td>\n      <td>86</td>\n      <td>67.72%</td>\n      <td>68.503937</td>\n      <td>31.496063</td>\n      <td>False</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>164</th>\n      <td>Fœlix consortium, or, A fit conjuncture of rel...</td>\n      <td>1663</td>\n      <td>71</td>\n      <td>0</td>\n      <td>0.00%</td>\n      <td>49</td>\n      <td>69.01%</td>\n      <td>69.014085</td>\n      <td>30.985915</td>\n      <td>False</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    "texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Publisher'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/miniconda3/envs/alchemy_nlp/lib/python3.8/site-packages/pandas/core/indexes/base.py:3802\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3801\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/miniconda3/envs/alchemy_nlp/lib/python3.8/site-packages/pandas/_libs/index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/miniconda3/envs/alchemy_nlp/lib/python3.8/site-packages/pandas/_libs/index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'Publisher'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# nonempty rows in Publisher column\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m texts[\u001B[43mtexts\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mPublisher\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mnotnull()]\n",
      "File \u001B[0;32m~/miniconda3/envs/alchemy_nlp/lib/python3.8/site-packages/pandas/core/frame.py:3807\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3806\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3807\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3809\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/miniconda3/envs/alchemy_nlp/lib/python3.8/site-packages/pandas/core/indexes/base.py:3804\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3804\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3806\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3808\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3809\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'Publisher'"
     ]
    }
   ],
   "source": [
    "# nonempty rows in Publisher column\n",
    "\n",
    "texts[texts['Publisher'].notnull()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepration of dataset for TF-IDF \n",
    "'''\n",
    "\n",
    "# drop empty rows\n",
    "\n",
    "texts = texts.dropna(how='all')\n",
    "\n",
    "# treat the content of each row in the column Text as a document for TF-IDF vectorization\n",
    "# create a list of documents\n",
    "\n",
    "documents = texts['Text'].tolist()\n",
    "\n",
    "sentences = lw11['Fragments'].values\n",
    "sentences #= [sent.split() for sent in sentences]\n",
    "\n",
    "\n",
    "Training for principles label\n",
    "\n",
    "# fill NaN with empty string\n",
    "\n",
    "lw11 = lw11.fillna('')\n",
    "lw11.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses the sentence \"Fragments\" as independent variable for principles training\n",
    "sentences_p = data['Title'].values\n",
    "\n",
    "# Set dependent variable here, \"if Principles\"\n",
    "Y_p = data['If Principles'].values\n",
    "\n",
    "# Splits datasets into 20% test data, 80% train data\n",
    "sentences_train_p, sentences_test_p, Y_train_p, Y_test_p = train_test_split(sentences_p, Y_p, test_size = .2, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# Uses the sentence \"Fragments\" as independent variable for lab/ops training\n",
    "sentences_l = data['Title'].values\n",
    "\n",
    "# Set dependent variable here, \"Lab/Ops\"\n",
    "Y_l = data['If Labs/Ops'].values\n",
    "\n",
    "# Splits datasets into 20% test data, 80% train data\n",
    "sentences_train_l, sentences_test_l, Y_train_l, Y_test_l = train_test_split(sentences_l, Y_l, test_size = .2, random_state = 12)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize de sentences for principles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "# Creates a TF-IDF vectorizer and fits it onto the training sentences\n",
    "# vectorizer = TfidfVectorizer(stop_words='english', max_features= 1000)\n",
    "vectorizer_p = TfidfVectorizer()\n",
    "vectorizer_p.fit(sentences_train_p) # fit the model only on training data\n",
    "\n",
    "# Creates new independent variables that are transformed with vectorizer\n",
    "X_train_p = vectorizer_p.transform(sentences_train_p) # transform the training data to a document-term matrix\n",
    "X_test_p  = vectorizer_p.transform(sentences_test_p) # transform the testing data to a document-term matrix\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "# Fits classifier onto training data\n",
    "classifier_p = LogisticRegression()\n",
    "classifier_p.fit(X_train_p, Y_train_p)\n",
    "\n",
    "# Creates score based on test data\n",
    "score_p = classifier_p.score(X_test_p, Y_test_p)\n",
    "print(\"Accuracy:\", score_p)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for lab/ops label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Creates a TF-IDF vectorizer and fits it onto the training sentences\n",
    "# vectorizer = TfidfVectorizer(stop_words='english', max_features= 1000)\n",
    "vectorizer_l = TfidfVectorizer()\n",
    "vectorizer_l.fit(sentences_train_l) # fit the model only on training data\n",
    "\n",
    "# Creates new independent variables that are transformed with vectorizer\n",
    "X_train_l = vectorizer_l.transform(sentences_train_l) # transform the training data to a document-term matrix\n",
    "X_test_l  = vectorizer_l.transform(sentences_test_l) # transform the testing data to a document-term matrix\n",
    "print('finished')"
   ],
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.058823529411764705\n"
     ]
    }
   ],
   "source": [
    "# Fits classifier onto training data\n",
    "classifier_l = LogisticRegression()\n",
    "classifier_l.fit(X_train_l, Y_train_l)\n",
    "\n",
    "# Creates score based on test data\n",
    "score_l = classifier_p.score(X_test_l, Y_test_l)\n",
    "print(\"Accuracy:\", score_l)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alchemy_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}